{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2140fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f53a4ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup device-agnostic code \n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"cpu\" # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "900d348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "n_cpu = 8\n",
    "latent_dim = 100\n",
    "img_size = 28\n",
    "channels = 1\n",
    "sample_interval = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ddc16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ChineseMNISTDataset(Dataset):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv('../data/chinese_mnist/chinese_mnist.csv')\n",
    "        self.img_dir = '../data/chinese_mnist/data/data'\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        suite_id,sample_id,code,value, _ = self.img_labels.iloc[idx]\n",
    "        img_name = 'input_{0}_{1}_{2}.jpg'.format(suite_id,sample_id, code)\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = read_image(img_path)\n",
    "        label = code\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b3c6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "img_shape = (channels, img_size, img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "mps = True if torch.backends.mps.is_available() else False\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acea480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "                                \n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "if mps:\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "    adversarial_loss.to(device)\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='../data/mnist',\n",
    "    train=True,\n",
    "    transform=transform, \n",
    "    #把灰階從0~255壓縮到0~1\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Configure data loader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size= batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc3fa061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14bcda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "print(Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9e28311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/938] [D loss: 0.694808] [G loss: 0.716732]\n",
      "[Epoch 0/200] [Batch 400/938] [D loss: 0.400874] [G loss: 1.211501]\n",
      "[Epoch 0/200] [Batch 800/938] [D loss: 0.510320] [G loss: 0.557101]\n",
      "[Epoch 1/200] [Batch 262/938] [D loss: 0.350319] [G loss: 1.529854]\n",
      "[Epoch 1/200] [Batch 662/938] [D loss: 0.382688] [G loss: 1.048612]\n",
      "[Epoch 2/200] [Batch 124/938] [D loss: 0.274201] [G loss: 1.199351]\n",
      "[Epoch 2/200] [Batch 524/938] [D loss: 0.283112] [G loss: 1.149648]\n",
      "[Epoch 2/200] [Batch 924/938] [D loss: 0.300300] [G loss: 1.187628]\n",
      "[Epoch 3/200] [Batch 386/938] [D loss: 0.294107] [G loss: 1.461770]\n",
      "[Epoch 3/200] [Batch 786/938] [D loss: 0.390284] [G loss: 3.344377]\n",
      "[Epoch 4/200] [Batch 248/938] [D loss: 0.253754] [G loss: 1.882399]\n",
      "[Epoch 4/200] [Batch 648/938] [D loss: 0.215256] [G loss: 2.092250]\n",
      "[Epoch 5/200] [Batch 110/938] [D loss: 0.670947] [G loss: 5.730659]\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a5e2255e14513bd463d560cf9a8ee1062d57084a6ce6cd1a345293de4c04e81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
